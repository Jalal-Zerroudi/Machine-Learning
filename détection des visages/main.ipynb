{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from PyQt6.QtWidgets import QApplication, QLabel, QPushButton, QVBoxLayout, QWidget\n",
    "from PyQt6.QtGui import QImage, QPixmap\n",
    "from PyQt6.QtCore import QTimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetectionApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Configuration de l'interface\n",
    "        self.setWindowTitle(\"Détection de Visage - App Moderne\")\n",
    "        self.setGeometry(100, 100, 800, 600)\n",
    "\n",
    "        # Layout principal\n",
    "        self.layout = QVBoxLayout()\n",
    "\n",
    "        # Label pour afficher la vidéo\n",
    "        self.video_label = QLabel(self)\n",
    "        self.layout.addWidget(self.video_label)\n",
    "\n",
    "        # Bouton Quitter\n",
    "        self.quit_button = QPushButton(\"Quitter\")\n",
    "        self.quit_button.clicked.connect(self.close_app)\n",
    "        self.layout.addWidget(self.quit_button)\n",
    "\n",
    "        self.setLayout(self.layout)\n",
    "\n",
    "        # Initialisation de la webcam\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Initialisation de Mediapipe\n",
    "        self.mp_face_detection = mp.solutions.face_detection\n",
    "        self.face_detection = self.mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "        # Timer pour la mise à jour de la vidéo\n",
    "        self.timer = QTimer()\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        self.timer.start(30)  # 30ms pour un affichage fluide\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        # Conversion pour Mediapipe (BGR → RGB)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_detection.process(frame_rgb)\n",
    "\n",
    "        # Dessiner les boîtes des visages détectés\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                h, w, _ = frame.shape\n",
    "                x, y, w_box, h_box = int(bboxC.xmin * w), int(bboxC.ymin * h), int(bboxC.width * w), int(bboxC.height * h)\n",
    "                cv2.rectangle(frame, (x, y), (x + w_box, y + h_box), (0, 255, 0), 3)\n",
    "\n",
    "        # Convertir l'image pour PyQt\n",
    "        height, width, channel = frame.shape\n",
    "        bytes_per_line = 3 * width\n",
    "        qt_img = QImage(frame.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)\n",
    "        self.video_label.setPixmap(QPixmap.fromImage(qt_img))\n",
    "\n",
    "    def close_app(self):\n",
    "        self.cap.release()\n",
    "        self.timer.stop()\n",
    "        self.close()\n",
    "\n",
    "# Lancer l'application\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = FaceDetectionApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
